{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3cv9-x_gKat"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP_2022/blob/main/03%20Machine%20Learning/notebooks/07-Decision-Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6TaZpW8qma6"
      },
      "source": [
        "# Árboles de decisión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLY1XR5rjmL4"
      },
      "source": [
        "<img src=\"https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/img/DT.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHVlH2Bud4Da"
      },
      "source": [
        "En esta notebook usaremos el clasificador [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) de scikit-learn.\n",
        "\n",
        "Primero, observaremos algunas caracteristicas generales del método y después, lo usaremos en un problema de clasificación con un dataset clásico del machine learning.\n",
        "\n",
        "🎯 Los objetivos de esta notebook son:\n",
        "\n",
        "1. Familiarizarse con el uso del algoritmo y sus hiperparámetros principales.\n",
        "2. Percibir las particularidades de este algoritmo y compararlo con otros algoritmos.\n",
        "3. Usar el algoritmo en un dataset real.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcheG_cRD9_a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XJ2MgCSHFmBY"
      },
      "outputs": [],
      "source": [
        "#@title Función para graficar la frontera de decisión\n",
        "\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "import numpy as np\n",
        "\n",
        "def graficar_FD(X,y,clf,h=0):\n",
        "    '''\n",
        "    X es todas las instancias las cuales incluiremos en el gráfico\n",
        "    '''\n",
        "    assert X.shape[1] == 2   # Sólo funciona para datos en dimensión 2\n",
        "    feature_1, feature_2 = np.meshgrid(\n",
        "    np.linspace(X[:,0].min()-h, X[:, 0].max()+h),\n",
        "    np.linspace(X[:, 1].min()-h, X[:, 1].max()+h)\n",
        "    )\n",
        "    grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n",
        "    y_grid_pred = clf.predict(grid)\n",
        "    y_grid_pred = y_grid_pred.reshape(feature_1.shape)\n",
        "    display = DecisionBoundaryDisplay(\n",
        "    xx0=feature_1, xx1=feature_2, response=y_grid_pred\n",
        "    )\n",
        "    display.plot()\n",
        "    display.ax_.scatter(\n",
        "        X[:, 0], X[:, 1], c=y, edgecolor=\"black\"\n",
        "    )\n",
        "    plt.show()\n",
        "    return display.ax_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6vhe29d5uVK"
      },
      "source": [
        "El módulo `dtreeviz` es útil para la visualización de árboles de decisión y la interpretación de modelos ([documentación](https://github.com/parrt/dtreeviz))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKhWGzhP5hNG"
      },
      "outputs": [],
      "source": [
        "!pip install -qq dtreeviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHm65FMfuY4K"
      },
      "source": [
        "# Ejemplo 1: Un ejemplo ilustrativo\n",
        "\n",
        "Con este ejemplo, exploraremos el uso básico del álgoritmo y observaremos las características y particularidades del clasificador DT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tia5xfFLylY"
      },
      "source": [
        "## 1. Datos linealmente separables con una línea horizontal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4D3IsxALKe2"
      },
      "source": [
        "### Conjunto de datos\n",
        "\n",
        "En este primer ejemplo generamos un conjunto de datos linealmente separables con `make_blobs`. Estos datos pueden ser separados con una línea vértical, es decir con una condición de tipo\n",
        "\n",
        "* Si $x>\\alpha$ entonces $(x,y)\\in\\text{clase}_0$.\n",
        "* Si $x<\\alpha$ entonces $(x,y)\\in\\text{clase}_1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9r0a-hD4Uli"
      },
      "source": [
        "Primero, generamos y visualizamos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqZPXmUYN9ro"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, y = make_blobs(n_samples=600,centers=2,random_state=31)\n",
        "\n",
        "# colors = {0: 'blue', 1: 'red'} # Forzar a que cada clase tenga un color determinado\n",
        "colors = ['blue' if yi==0 else 'red' for yi in y] # Forzar a que cada clase tenga un color determinado\n",
        "\n",
        "plt.figure()\n",
        "# plt.scatter(X[:,0],X[:,1],c=[colors[yi] for yi in y])\n",
        "plt.scatter(X[:,0],X[:,1],c=colors)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkBPTaa84anV"
      },
      "source": [
        "Dividimos los datos en *train/test*. Entrenamos el árbol de decisión usando la implementación de scikit-learn `sklearn.tree.DecisionTreeClassifier`. Realizamos la predicción sobre el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N36oEEHK4YK4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101) # 70% entrenamiento y 30% prueba\n",
        "\n",
        "clf = DecisionTreeClassifier()  # Inicializar el modelo con los hiperparámetros por defecto\n",
        "clf = clf.fit(X_train,y_train)  # Entrenar el modelo\n",
        "y_pred = clf.predict(X_test)    # Predecir las etiquetas para el conjunto de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQwJ_57zLOBE"
      },
      "source": [
        "### Entrenamiento y evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVBqAM525NRI"
      },
      "source": [
        "Como es de esperar, obtenemos el 100% en todas las métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paSzESRGOEOh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),3)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx66pAxiLCPb"
      },
      "source": [
        "### Visualización del árbol (opcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CawGwBEF5Yhs"
      },
      "source": [
        "Veamos el árbol de decisión usando [`export_text`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_text.html) del módulo `tree` de scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no7nskN-OhcG"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,feature_names=['x','y'])\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkmSBhGdPPS1"
      },
      "outputs": [],
      "source": [
        "_ = graficar_FD(X,y,clf,h=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArjtpE4M3nEh"
      },
      "source": [
        "## Datos linealmente separables con una línea no vertical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkozO0Ay6UD1"
      },
      "source": [
        "Transformamos los datos para ahora sean separables con línea no horizontal. Para esto, rotamos cada punto un ángulo $\\theta=\\frac{\\pi}{4}=45°$, además, trasladamos la clase *positiva* con el vector $z=(-1,-2)$.\n",
        "\n",
        "**Ocultamos el código por limpieza**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AsmIGzTx6TmQ"
      },
      "outputs": [],
      "source": [
        "#@title Conjunto de datos\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "theta = np.pi/4 # Ángulo de rotación\n",
        "R = np.array([[np.cos(theta),-np.sin(theta)],[np.sin(theta),np.cos(theta)]]) # Matriz de rotación\n",
        "\n",
        "Xr = np.transpose(R@np.transpose(X)) # Rotamos el dataset\n",
        "\n",
        "idxs = np.where(y==1)[0]   # Obtenemos los índices donde y=1\n",
        "\n",
        "Xr[idxs,:] = Xr[idxs,:] + np.array([-1,-2])\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(9,5),sharey=True)\n",
        "axs[0].scatter(X[:,0],X[:,1],c=['blue' if yi==0 else 'red' for yi in y])\n",
        "axs[0].set_title(\"Original dataset\")\n",
        "axs[1].scatter(Xr[:,0],Xr[:,1],c=['blue' if yi==0 else 'red' for yi in y])\n",
        "axs[1].set_title(\"Transformed dataset\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehKSVwpH_r0B"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xr, y, test_size=0.3, random_state=101) # 70% training and 30% test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Mgg6M1NZ9m"
      },
      "source": [
        "### Entrenamiento y evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwjCPJ_6NgoY"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier()  # Create Decision Tree classifier object\n",
        "clf = clf.fit(X_train,y_train)  # Train Decision Tree Classifier\n",
        "y_pred = clf.predict(X_test)    # Predict the response for test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYrghH9rC-F9"
      },
      "source": [
        "Dados que los datos siguen siendo linealmente separables, seguimos obteniendo el 100% en todas las métricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lSQ8DO4_zwA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),5)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True, fmt='g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOcQyoF-NomE"
      },
      "source": [
        "### Visualización del árbol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNNNHtZ2DHm-"
      },
      "source": [
        "Sin embargo, el árbol empieza a hacerse más complejo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK2bQQc5_4yd"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,feature_names=['x','y'])\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0smc2XnR1F3"
      },
      "source": [
        "La frontera de decisión no es la que esperaríamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx8i-5bGCUUq"
      },
      "outputs": [],
      "source": [
        "_ = graficar_FD(Xr,y,clf,h=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMZFacpJqyQj"
      },
      "source": [
        "Como podemos ver, este clasificador no separa con una línea en general, aún si los datos son linealmente separables. **Los árboles de decisión obtienen una FD compuesta de segmentos de línea verticales y horizontales.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11W12kCidBep"
      },
      "source": [
        "### Efecto de perturbaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr0pJ-nKSfQo"
      },
      "source": [
        "Ahora, observemos el efecto de perturbar levemente el conjunto de datos. ¿Qué le pasa al arbol de decisión?\n",
        "\n",
        "Este tipo de perturbaciones pueden ocurrir como resultado de errores de medición o de la presencia de outliers.\n",
        "\n",
        "Movemos un par de puntos cerca de la FD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hUiUrdOdH9b"
      },
      "outputs": [],
      "source": [
        "Xrp = Xr.copy()\n",
        "Xrp[192] = Xrp[192] + np.array([-1,-2])\n",
        "Xrp[486] = Xrp[486] + np.array([2,1])\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(9,5),sharey=True)\n",
        "axs[0].scatter(Xr[:,0],Xr[:,1],c=['blue' if yi==0 else 'red' for yi in y])\n",
        "axs[0].set_title(\"Original dataset\")\n",
        "axs[1].scatter(Xrp[:,0],Xrp[:,1],c=['blue' if yi==0 else 'red' for yi in y])\n",
        "axs[1].set_title(\"Perturbed dataset\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiWGKgphQJFU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xrp, y, test_size=0.3, random_state=101) # 70% training and 30% test\n",
        "\n",
        "clf = DecisionTreeClassifier()  # Create Decision Tree classifier object\n",
        "clf = clf.fit(X_train,y_train)  # Train Decision Tree Classifier\n",
        "y_pred = clf.predict(X_test)    # Predict the response for test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl_M9fD2QJFW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),5)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True, fmt='g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5f2V5DEQJFX"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,feature_names=['x','y'])\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbmVDMdXQJFY"
      },
      "outputs": [],
      "source": [
        "_ = graficar_FD(Xrp,y,clf,h=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOHwPFOmX7zx"
      },
      "source": [
        "# Ejemplo 2: MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew7tZerDkAYF"
      },
      "source": [
        "Ver la diferencia entre normalizar o no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le5lbPpXX_oj"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "X = digits.data\n",
        "y = digits.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG9-Y5TVYWxR"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lpuc3WXfSJFc"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy entrenamiento: {clf.score(X_train,y_train)}\")\n",
        "print(f\"Accuracy prueba: {clf.score(X_test,y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gWKa8KHS99Y"
      },
      "source": [
        "Viendo las métricas, ¿hay señales de entrenamiento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMzvZFqlYwRN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred, average='macro'),3)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred, average='macro'),3)}\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True, fmt='g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CIDRJC9Y7NU"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "\n",
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,feature_names=[f'pixel_{j+1}' for j in range(X.shape[1])])\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uP__ydLXPNJ"
      },
      "source": [
        "### No es necesaria la normalización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bquVwsUweOax"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "\n",
        "# ----- Normalizando ----\n",
        "pl = Pipeline([('scl',MinMaxScaler()),\n",
        "               ('clf',DecisionTreeClassifier())])\n",
        "pl.fit(X_train,y_train)\n",
        "print(f\"Accuracy de prueba (Normalizando): {pl.score(X_test,y_test)}\")\n",
        "\n",
        "# ---- Sin normalizar ----\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "print(f\"Accuracy de prueba (Sin normalizar): {clf.score(X_test,y_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taNnvpVFfgTS"
      },
      "source": [
        "### Efecto de los hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ijxtqwiUTuU"
      },
      "source": [
        "Veamos cuál es el efecto en el accuracy de cambiar el parámetro `max_depth`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdTS7E0-TG1T"
      },
      "outputs": [],
      "source": [
        "depths = [2,3,4,5,6,7,8,9,10,11]\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for d in depths:\n",
        "    clf = DecisionTreeClassifier(max_depth=d)\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    train_scores.append(clf.score(X_train,y_train))\n",
        "    test_scores.append(clf.score(X_test,y_test))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(depths,train_scores,label='Entrenamiento')\n",
        "plt.plot(depths,test_scores,label='Prueba')\n",
        "plt.axhline(0.835,color='gray',linestyle='--')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY2wWtUTWT_X"
      },
      "source": [
        "Con la ayuda de gridsearch, veamos cuál es la mejor profundidad que podemos obtener"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKOmR3XTUzuC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "gs = GridSearchCV(estimator = DecisionTreeClassifier(),\n",
        "                  param_grid = {'max_depth': depths})\n",
        "gs.fit(X_train,y_train)\n",
        "print(gs.best_params_)\n",
        "print(f\"Accuracy de prueba con el mejor clasificador: {gs.best_estimator_.score(X_test,y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0uXYModWQsy"
      },
      "source": [
        "### Comparación con otros algoritmos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX-9U_75WS-m"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import time\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
        "\n",
        "dt_times = []\n",
        "for j in range(5):\n",
        "    start = time.time()\n",
        "    clf = DecisionTreeClassifier(max_depth=None)\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "    end = time.time()\n",
        "    dt_times.append(end-start)\n",
        "print(f\"Tiempo promedio de ejecución DT: {np.mean(dt_times)}\")\n",
        "\n",
        "svm_times = []\n",
        "for j in range(5):\n",
        "    start = time.time()\n",
        "    clf = SVC(kernel='linear')\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "    end = time.time()\n",
        "    svm_times.append(end-start)\n",
        "print(f\"Tiempo promedio de ejecución SVM: {np.mean(svm_times)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiHH6O5dbgM9"
      },
      "source": [
        "¿Cómo se compara el rendimiento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08bgv1Y0bmTI"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "\n",
        "clf = SVC()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "print(f\"Accuracy de prueba (SVM): {clf.score(X_test,y_test)}\")\n",
        "\n",
        "print(f\"Accuracy de prueba (DT): {gs.best_estimator_.score(X_test,y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l744DLSs6FIg"
      },
      "source": [
        "# Ejemplo 3: PIMA Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VupVs1qxEAIR"
      },
      "source": [
        "## 1. El conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3vFmHPULcpU"
      },
      "source": [
        "Este dataset fue creado por el *National Institute of Diabetes and Digestive and Kidney Diseases* de Estados Unidos. El objetivo del dataset es predecir el diagnostico de cuándo un paciente tiene diabetes o no, basado en ciertas mediciones incluidas en el dataset. Varias restricciones fueron usadas en la selección de estas instancias para filtrar el dataset. En particular, se trata pacientes femeninas de al menos 21 años de edad pertenecientes al grupo indígena Pima de Arizona.\n",
        "\n",
        "Las variables incluidas son el numero de embarazos la paciente ha tenido, su BMI, nivel de insulina, edad, entre otras.\n",
        "\n",
        "El dataset se encuentra en https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvSDcCiBD_4M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/diabetes.csv'\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OBIK856IEcw"
      },
      "source": [
        "## Entrenar el clasificador y resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qMqoQT3IPXY"
      },
      "source": [
        "Escogemos las *features* que usaremos y definimos el dataset de features y el vector de etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOUwwCd5S3DO"
      },
      "outputs": [],
      "source": [
        "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
        "\n",
        "X = df[feature_cols].values    # Features\n",
        "y = df['label'].values         # Target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOLVREgOIhWN"
      },
      "source": [
        "Dividimos los datos en train/test. Entrenamos el árbol de decisión usando la implementación de scikit-learn sklearn.tree.DecisionTreeClassifier. Realizamos la predicción sobre el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpZUvwi7Ig1u"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsso9OE3BVk_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),5)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")\n",
        "\n",
        "target_labels = ['no diabetes','diabetes']\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True, fmt='g',\n",
        "            xticklabels=target_labels,\n",
        "            yticklabels=target_labels)\n",
        "s_cm.set(xlabel='Predicted',ylabel='Real')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXSNV3Kej-zy"
      },
      "source": [
        "## Importancia de las features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "004cEhuKaxFb"
      },
      "source": [
        "Podemos obtener la importancia de las features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTVRCjRpaw1z"
      },
      "outputs": [],
      "source": [
        "clf.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4RvkQpOamub"
      },
      "outputs": [],
      "source": [
        "importances_df = pd.DataFrame({'feature':feature_cols,'importancia':np.round(clf.feature_importances_,3)})\n",
        "importances_df.sort_values(by='importancia',ascending=False,inplace=True)\n",
        "importances_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHIxJ_6Wj6dH"
      },
      "source": [
        "## Visualizaciones de los árboles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77CcvUVsSghj"
      },
      "source": [
        "Al visualizar árboles de decisión recuerda que el escalamiento no es necesario, en general. Si decides escalar, esto tiene repercusiones en la visualización del árbol."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUt9Z3-WlEvk"
      },
      "source": [
        "### Con scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as_iRGyHj8h0"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,\n",
        "                                       feature_names=feature_cols)\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoyVuldWk1I6"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "fig = plt.figure(figsize=(25,20))   # Definimos una figura más grande para que quepa\n",
        "_ = plot_tree(clf, feature_names=feature_cols,\n",
        "                   class_names=['0','1'],\n",
        "                   filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbHmh8pCWmzi"
      },
      "source": [
        "### Using [graphviz](https://graphviz.org/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d_KAeh3SOpv"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "graph.write_png('diabetes.png')\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3PQex_sRsnz"
      },
      "source": [
        "### Using [dtreeviz](https://github.com/parrt/dtreeviz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvKybSONxSut"
      },
      "outputs": [],
      "source": [
        "from dtreeviz import model\n",
        "\n",
        "X_scl = pl['selector'].transform(X)\n",
        "\n",
        "ct = model(pl['clasificador'], X_scl, y, feature_names = feature_cols)\n",
        "ct.view(fontname='DejaVu Sans')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_8WgZDGWjWm"
      },
      "source": [
        "Si queremos salvar la imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq9Rqb3aWl85"
      },
      "outputs": [],
      "source": [
        "v = ct.view(fontname='DejaVu Sans')\n",
        "v.save(\"tree.svg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH4LAHlzH97g"
      },
      "source": [
        "#⭕ **Práctica**:\n",
        "\n",
        "¿Puedes subir las métricas de desempeño de este clasificador en este dataset? A continuación hay algunas opciones que puedes probar:\n",
        "\n",
        "* Observar la variable 'bmi', tiene valores 0, ¿qué sentido tienen estos?\n",
        "    * Puedes quitar esas instancias.\n",
        "    * Puedes quitar la variable.\n",
        "* Cambiar el conjunto de features, ya sea manualmente o con algún método como [VarianceThreshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold), [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html), etc.\n",
        "* Realizar un gridsearch en los parámetros del clasificador: `max_depth`, `criterion`, `min_samples_leaf`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwbg6Q2uYs85"
      },
      "source": [
        "A continuación se muestra una estrategia para obtener alrededor de 75% de accuracy.\n",
        "\n",
        "Esta estrategia usa un imputador para reemplazar los valores 0 con el promedio. Además, se hace selección de features. Todo se junta en un pipeline.\n",
        "\n",
        "**Además, realizamos un gridsearch en un pipeline.**\n",
        "\n",
        "Puedes probar modificando algunos pasos para buscar obtener un mejor rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_UHvMG_UADb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/diabetes.csv'\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7MUiy728wC1"
      },
      "outputs": [],
      "source": [
        "feature_names = df.columns.to_list()[:-1]\n",
        "\n",
        "print(f\"Nombres de las features: {feature_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq-gOmZJ8q1a"
      },
      "outputs": [],
      "source": [
        "X = df.loc[:,feature_names].values\n",
        "y = df['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyBoAydZQX-w"
      },
      "source": [
        "### ⚡ GridSearch con pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tJwQ9WFbJLX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"selector__threshold\": [0,0.1,0.2,0.5],\n",
        "    \"clasificador__criterion\": ['gini','entropy'],\n",
        "    \"clasificador__max_depth\": [None,10],\n",
        "    \"clasificador__min_samples_split\": [2,3,4]\n",
        "}\n",
        "\n",
        "search = GridSearchCV(pl, param_grid, n_jobs=2)\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
        "print(search.best_params_)\n",
        "\n",
        "best_clf = search.best_estimator_\n",
        "\n",
        "print(f\"Accuracy en el entrenamiento: {best_clf.score(X_train,y_train)}\")\n",
        "print(f\"Accuracy en la prueba: {best_clf.score(X_test,y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuklND0fX1TF"
      },
      "outputs": [],
      "source": [
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),3)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
